You are the manager of a data science team whose goal is to extract actionable insights from a given data.
You have access to a team of highly skilled data scientists that can answer complex questions about the data.
You call the shots and they do the work.
Your ultimate deliverable is a report that summarizes the findings and makes hypothesis for any trend or anomaly that was found.

## Given the following meta data:
<meta>
<description>The HR dataset is a comprehensive collection of employee-related data gathered over time to help the HR team make informed decisions about workforce management, recruitment, retention, and performance improvement. This dataset captures various aspects of an employeeâ€™s lifecycle within the organization, from hiring to exit, and includes key metrics and performance indicators.</description>
<goal>Reduce Employee Turnover and Improve Retention Strategies.</goal>
<persona>HR Data Analyst.</persona>
<dataset_name>HR management</dataset_name>
<indicator_list>[{'name': 'missing_inconsistent_data', 'description': 'Any missing values in critical fields like assigned_group, assignee, resolved_date, or requester should be flagged.', 'threshold': 'Rows with over 5% missing critical fields should be excluded or revisited.'}, {'name': 'sla_breach_analysis', 'description': 'Identify instances where SLA (Service Level Agreement) breaches occur, particularly in high-priority tickets.', 'threshold': 'More than 10% of high-priority tickets should be reviewed for SLA compliance.'}, {'name': 'status_discrepancies', 'description': "Check for inconsistencies in the status field, such as tickets marked as 'resolved' but still have open issues.", 'threshold': "Any tickets with status 'resolved' but unresolved dates should be flagged for review."}, {'name': 'time_to_resolution_outliers', 'description': 'Analyze the time_to_resolution for outliers that significantly exceed the average resolution time.', 'threshold': 'Tickets with time_to_resolution greater than 2 standard deviations from the mean should be investigated.'}, {'name': 'priority_distribution', 'description': 'Examine the distribution of request types across different priority levels to ensure balanced handling.', 'threshold': 'Any priority level with less than 5% of total tickets should be flagged for potential review.'}, {'name': 'category_subcategory_mismatch', 'description': 'Identify tickets where the category does not align with the subcategory assigned.', 'threshold': 'Any tickets with mismatched category and subcategory should be reviewed for accuracy.'}, {'name': 'assignee workload imbalance', 'description': 'Monitor the distribution of tickets among assignees to identify potential workload imbalances.', 'threshold': 'Any assignee with more than 20% of total tickets should be flagged for workload review.'}, {'name': 'impact assessment', 'description': 'Evaluate the impact ratings assigned to tickets to ensure they are consistent with the request type and priority.', 'threshold': 'Any tickets with high impact but low priority should be reviewed for potential misclassification.'}, {'name': 'resolution_description completeness', 'description': 'Check for completeness and clarity in the resolution_description field to ensure proper documentation.', 'threshold': 'Any tickets with resolution descriptions shorter than 10 words should be flagged for review.'}, {'name': 'requester engagement', 'description': 'Analyze the frequency of requests from each requester to identify potential patterns or engagement issues.', 'threshold': 'Requesters with more than 5 open tickets should be flagged for follow-up.'}]</indicator_list>
</meta>

## Given the following schemas:
<schemas>
Column: employee_id (object)
  missing_count: 0
  unique_count: 1000
  top5_unique_values: ['E10000', 'E10671', 'E10658', 'E10659', 'E10660']
Column: name (object)
  missing_count: 0
  unique_count: 994
  top5_unique_values: ['Larry Carr', 'Andrew Rhodes', 'John Jones', 'Alexander Smith', 'Mark Mason']
Column: age (float64)
  missing_count: 0
  unique_count: 49
  min: 18.0
  max: 67.0
  mean: 41.026
  std: 13.461892383559846
Column: department (object)
  missing_count: 0
  unique_count: 9
  top5_unique_values: ['IT', 'HR', 'Legal', 'Operations', 'R&D']
Column: job_level (object)
  missing_count: 0
  unique_count: 9
  top5_unique_values: ['Intern', 'Mid', 'C-level', 'Manager', 'Senior']
Column: location (object)
  missing_count: 0
  unique_count: 7
  top5_unique_values: ['Bangalore', 'Remote', 'Tokyo', 'Berlin', 'New York']
Column: salary (float64)
  missing_count: 0
  unique_count: 992
  min: -92082.0
  max: 286001.0
  mean: 70261.375
  std: 25399.37761709351
Column: years_with_company (float64)
  missing_count: 0
  unique_count: 45
  min: -32.0
  max: 39.0
  mean: 19.201
  std: 11.381482202996985
Column: last_performance_rating (float64)
  missing_count: 0
  unique_count: 5
  min: 1.0
  max: 5.0
  mean: 2.996
  std: 1.4380723389496273
Column: is_remote (float64)
  missing_count: 0
  unique_count: 2
  min: 0.0
  max: 1.0
  mean: 0.485
  std: 0.5000250243988045
Column: promotion_last_2_years (float64)
  missing_count: 0
  unique_count: 2
  min: 0.0
  max: 1.0
  mean: 0.503
  std: 0.500241183071967
Column: left_company (float64)
  missing_count: 0
  unique_count: 2
  min: 0.0
  max: 1.0
  mean: 0.502
  std: 0.5002461856388775


Column 'employee_id' examples
    E10000
    E10001

Column 'name' examples
    Anthony Stone
    John Berry

Column 'age' examples
    47.0
    21.0

Column 'department' examples
    Finance
    HR

Column 'job_level' examples
    Director
    Junior

Column 'location' examples
    London
    New York

Column 'salary' examples
    56909.0
    98039.0

Column 'years_with_company' examples
    8.0
    21.0

Column 'last_performance_rating' examples
    4.0
    1.0

Column 'is_remote' examples
    0.0
    1.0

Column 'promotion_last_2_years' examples
    0.0
    1.0

Column 'left_company' examples
    0.0


</schemas>

## Do not repeat anything similar to these past questions:
<past_questions>
['Give me an overview of this dataset.']
</past_questions>

## Instructions:
* Write a list of questions to be solved by the data scientists in your team to explore my data and reach my goal.
* Explore diverse aspects of the data, and ask questions that are relevant to my goal.
* You must ask the right questions to surface anything interesting (trends, anomalies, etc.)
* Make sure these can realistically be answered based on the data schema.
* The insights that your team will extract will be used to generate a report.
* Each question should only have one part, that is a single '?' at the end which only require a single answer.
* Do not number the questions.
* You can produce at most 10 questions. Stop generation after that.
* score should be between 0 and 100 indicating the importance of the question to extract interesting insights for the goal
* justication should be a short sentence explaining why the question is important
* type should be either descriptive, diagnostic, prescriptive, or predictive
* add columns to consider for the question
* Most importantly, each question must be enclosed within <container><columns></columns><question></question<justification></justification><score></score><type></type></container> tags. Refer to the example response below:

Example response:
<container><question>What is the average age of the customers?</question><justification>Age is an important factor in determining customer preferences.</justification><score>80</score><type>descriptive</type><columns>age,name</columns></container>
<container><question>What is the distribution of the customers based on their age?</question><justification>Understanding the age distribution can help in targeting specific age groups.</justification><score>70</score><type>descriptive</type><columns>age,name</columns></container>

### Response:
